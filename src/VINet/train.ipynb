{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pwd = os.getcwd()\n",
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VIDataloader.VIDataloader import get_dataloader\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)), transforms.ToTensor(),\n",
    "])\n",
    "image_dir = os.path.join(pwd, \"train_images\", \"images\")\n",
    "mask_dir = os.path.join(pwd, \"train_images\", \"masks\")\n",
    "batch_size = 2\n",
    "\n",
    "dataloader = get_dataloader(image_dir, mask_dir, batch_size, transform)\n",
    "type(dataloader), len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Object(object):\n",
    "    pass\n",
    "opt = Object()\n",
    "opt.t_stride = 5\n",
    "opt.prev_warp = False\n",
    "opt.double_size = False\n",
    "opt.loss_on_raw = False\n",
    "opt.batch_norm = False\n",
    "opt.search_range = 0\n",
    "opt.no_cuda = False\n",
    "opt.model = 'vinet_final'\n",
    "opt.crop_size = 512\n",
    "opt.pretrain_path = None\n",
    "opt.no_lstm = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from math import exp\n",
    "\n",
    "def ssim(img1, img2, window_size=11, window_sigma=1.5, data_range=1.0, size_average=True):\n",
    "    window = create_window(window_size, window_sigma).to(img1.device)\n",
    "\n",
    "    mu1 = F.conv2d(img1, window, padding=window_size//2, groups=img1.shape[1])\n",
    "    mu2 = F.conv2d(img2, window, padding=window_size//2, groups=img1.shape[1])\n",
    "\n",
    "    mu1_sq = mu1.pow(2)\n",
    "    mu2_sq = mu2.pow(2)\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "\n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=window_size//2, groups=img1.shape[1]) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=window_size//2, groups=img1.shape[1]) - mu2_sq\n",
    "    sigma12 = F.conv2d(img1 * img2, window, padding=window_size//2, groups=img1.shape[1]) - mu1_mu2\n",
    "\n",
    "    c1 = (0.01 * data_range) ** 2\n",
    "    c2 = (0.03 * data_range) ** 2\n",
    "\n",
    "    ssim_map = ((2 * mu1_mu2 + c1) * (2 * sigma12 + c2)) / ((mu1_sq + mu2_sq + c1) * (sigma1_sq + sigma2_sq + c2))\n",
    "\n",
    "    if size_average:\n",
    "        return ssim_map.mean()\n",
    "    else:\n",
    "        return ssim_map.mean(1).mean(1).mean(1)\n",
    "\n",
    "\n",
    "def gaussian(window_size, sigma):\n",
    "    gauss = torch.Tensor([exp(-(x - window_size//2)**2 / (2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss / gauss.sum()\n",
    "\n",
    "\n",
    "def create_window(window_size, sigma):\n",
    "    _1D_window = gaussian(window_size, sigma).unsqueeze(1)\n",
    "    _2D_window = _1D_window.mm(_1D_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = _2D_window.expand(3, 1, window_size, window_size).contiguous()\n",
    "    return window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from model import generate_model\n",
    "from train import train\n",
    "\n",
    "criterion_L1 = nn.L1Loss()\n",
    "\n",
    "def get_optimizer(model, lr=0.001):\n",
    "    return optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "model = generate_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(10, dataloader, model, criterion_L1, ssim, get_optimizer, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
